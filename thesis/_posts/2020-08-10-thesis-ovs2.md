---
layout: post
title: On SMOTE
categories: [thesis]
description: >
  On basic philosophies of (relatively) traditional SMOTE algorithms!
sitemap: false
---

This post aims to explain how the SMOTE works and few famous (relatively) traditional SMOTE methods. Especially the philosophy underneath each methods will be explained through some codes. 
The great *imblearn* package will do everything for me, however, this post will be focusing on understading 'how' it works so most of the codes will be written without using the package.

* Introduction
* SMOTE
* Difficult to classify?
    * Borderline SMOTE
    * ADASYN
* Application
{:toc}


```python
#import libraries
## basic
import numpy as np
import pandas as pd
import time ; import os ;import warnings
## visualising
import plotly.express as px
import matplotlib.pylab as plt 
import seaborn as sns
## simulation settings
from sklearn.datasets import make_classification
from sklearn.decomposition import PCA

warnings.filterwarnings('ignore')
plt.style.use('ggplot')
%matplotlib inline
```


```python
# Data generation
## binary classified data set
X, y = make_classification(n_samples=10000, n_classes=2, n_features=5, weights=[0.1,0.9],
                           class_sep=1.2 ,n_informative=3, n_redundant=1, 
                           n_clusters_per_class=1, random_state=5959)
## pca for the visualisation
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

## to dataframe
df = pd.DataFrame(np.c_[X,X_pca,y])
df.rename(columns={0:'x1',1:'x2',2:'x3',3:'x4',4:'x5',5:'pc1',6:'pc2',7:'y'}, inplace=True)
df.loc[df['y']==1.0, 'class'] = 'majority'; df.loc[df['y']==0.0, 'class'] = 'minority'
print(df.shape)
df.head()
```

    (10000, 9)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>x3</th>
      <th>x4</th>
      <th>x5</th>
      <th>pc1</th>
      <th>pc2</th>
      <th>y</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.446927</td>
      <td>-0.805986</td>
      <td>-0.204370</td>
      <td>2.685763</td>
      <td>-0.995430</td>
      <td>-0.372509</td>
      <td>-1.573765</td>
      <td>1.0</td>
      <td>majority</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.021895</td>
      <td>0.416956</td>
      <td>0.605226</td>
      <td>1.006717</td>
      <td>-0.916373</td>
      <td>0.034447</td>
      <td>-0.113674</td>
      <td>1.0</td>
      <td>majority</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.600807</td>
      <td>0.735755</td>
      <td>0.691506</td>
      <td>-2.705368</td>
      <td>-0.157486</td>
      <td>1.899553</td>
      <td>4.071497</td>
      <td>1.0</td>
      <td>majority</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-2.247067</td>
      <td>-1.200999</td>
      <td>-0.047714</td>
      <td>2.896885</td>
      <td>-0.310396</td>
      <td>0.148855</td>
      <td>-2.401905</td>
      <td>1.0</td>
      <td>majority</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.161805</td>
      <td>0.591529</td>
      <td>0.902177</td>
      <td>0.991662</td>
      <td>-2.836921</td>
      <td>-1.790337</td>
      <td>0.933301</td>
      <td>1.0</td>
      <td>majority</td>
    </tr>
  </tbody>
</table>
</div>




```python
## plotting
sns.scatterplot(x='pc1', y='pc2', data=df, hue="class", linewidth=0 , legend='full',palette='hls')
plt.xlabel("$PC_1$"); plt.ylabel("$PC_2$")
plt.title("Simulated Dataset")
```




    Text(0.5, 1.0, 'Simulated Dataset')




![png](output_3_1.png)


We are interested in matching the sizes of majority class and the minority class. And in OVERSAMPLING method, we only considers how to generate more **minority** samples from given data.
The very simplest way will be *random generation*, which is to generate any data points and name them to be the minority! However, it will probably make noises rather than some qualified, usefull samples.
I'll just leave the package codes here.

**imblearn package : RandomOverSampler**

|parameters|description|
|------|---|
|sampling_strategy|float = ratio (# of minority / # of samples in the majority after resampling)|
||str = auto (not minority), majority, not minority, not majority, all|
||dict = dictionary mapping|
|random_state|int|
 


```python
from imblearn.over_sampling import RandomOverSampler
# oversampling to make the balance
over = RandomOverSampler(0.5)
X_os, y_os = over.fit_sample(df[['pc1','pc2']], df['y'])
# comparison dataset
def sampled(x,y):
    data = pd.concat([x,y],axis=1)
    data.loc[data['y']==1.0, 'class'] = 'majority'; data.loc[data['y']==0.0, 'class'] = 'minority'
    return data
com = sampled(X_os,y_os)
```


```python
##plotting
f, axes = plt.subplots(1, 2, sharex=True, sharey=True)
f.set_size_inches((12, 5)) 

sns.scatterplot(x='pc1', y='pc2', data=df, hue="class", linewidth=0 , legend=False,palette='hls', ax=axes[0])
sns.scatterplot(x='pc1', y='pc2', data=com, hue="class", linewidth=0 , legend=False,palette='hls', ax=axes[1])
axes[0].set(xlabel='$PC_1$', ylabel='$PC_2$',title="Original")
axes[1].set(xlabel='$PC_1$', ylabel='$PC_2$',title="Random Oversampling")
plt.show()
```


![png](output_6_0.png)



```python

```
