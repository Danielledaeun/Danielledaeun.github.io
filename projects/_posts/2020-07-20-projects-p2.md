---
layout: post
title: Project 2. COPD exacerbation prediction
categories: [projects, p2]
description: >
  Built a classification models for the imbalanced data set.
sitemap: false
---

This post will be elaborating the whole process and thoughts on the building prediction models with imbalanced target. Due to the confidential issue, the details on data set will not be provided, however, I am quite sure that you will get the gist of my work at the end of reading this post! 
 
1. Introduction
2. Analysis Flow
3. Data Preparation
	* Resampling
4. Models
	* Hyperparameters tuning
5. Validation
	* Cross validation with SMOTE
6. Results
7. Further
	* Improvments
	* comments
{:toc}

## Introduction
Chronic Obstruction Pulmonary Disease(COPD) is a chronic inflammatory lung disease that causes obstructed airflow from the lungs. As it's *chronic*, people hope to keep patients from the **acute** case because there's no way to eradicate the disease. Acute cases can occur several times for a patient, that being said one might be intriguing in finding the factor that causes the exacerbation and calculating the updated probability of experiencing acute cases! This project tries to reach there using patients' previous medical records and the air pollutant information.

Amid all of the concerns on building decent prediction models, the main concerns on this project was *to find a proper way to tackle the imbalanced problem*. Since the acute cases are relatively rare compared to the ordinary COPD cases, *almost about less than 10%*, some resampling methods are considered. 

## Analysis Flow
```mermaid
graph LR
A[Data Preparation] --> B[Resampling]
B --> C[Modeling]
C --> D[Validation]
D --> F(finalisaion)
```
Roughly, the analysis followed the process above. Usually, the **Data Preparation** takes the longest time and it should be. As there is nothing like free gift : you should tune the variables(dtypes), most of the time you should create ones, and set your target with fine and accurate definition.  

After dealing with some medical data sets, I felt the definition matters over all of the other factors in the analysis (at least in this field). Defining the variables and subselecting the data set for the actual analysis required so many discussions and considerations. For this project, those processes went relatively smoothely because it was all set. This project is a subsequent study of [link here].

Reviewing the previous studies, I've notices several points to improve : a) resampling method and b) models themselves. The previous study also applied SMOTE but in a slightly different way from that of current usages. The previous SMOTE still kept the imbalance in quite substantive ratio, which might have not fully improved the classification. Also, the implemented models were mere naive traditional machine learning models without tunings. Taking these two into consideration, this project focused on improving the f1-score in terms of appling current and updated machine learning skills on the same data set.  

## Data Preparation
It should be natural to introduce at least some variables in the data set (for the sake of both credibility and  the convenience of explanation), however, it will not be provided in this post as it's confidential. All that I can provide for the further elaboration is that the data set contains almost every medical records of COPD patients in South Korea of certain period: which are medications usage, symptoms, types of clinics, hospitalisation records and so on. Also this data set contains FEV scores and CAT scores of each patients(which are medical indexes on the lung capacity) which are known to be crucial in classification according to the domain knowledge.  


### Variable selection

### Resampling

## Models

tree-based

## Validation
### Cross validation with SMOTE
[Cross Validation]({% link p2/_posts/2019-01-01-p2-cv.md %})

## Results and comments
